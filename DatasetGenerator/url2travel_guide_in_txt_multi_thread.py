import os
import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import requests
import json
from dotenv import load_dotenv
import os
from typing import List, Dict
import time
import shutil
import re
import threading
from queue import Queue
from selenium.common.exceptions import TimeoutException

# def extract_dynamic_itinerary(url, output_file, timeout=15, proxy=None):
#     """
#     å¢å¼ºç‰ˆåŠ¨æ€å†…å®¹æå–å‡½æ•°ï¼ˆå¸¦ä»£ç†æ”¯æŒå’Œå¼‚å¸¸é‡è¯•æœºåˆ¶ï¼‰
#     :param url: ç›®æ ‡URL
#     :param output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
#     :param timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
#     :param proxy: ä»£ç†è®¾ç½®ï¼Œæ ¼å¼ä¸º "ip:port" æˆ– "username:password@ip:port"
#     :return: æ˜¯å¦æˆåŠŸ
#     """
#     chrome_options = Options()
    
#     # åŸºç¡€æ— å¤´æ¨¡å¼é…ç½®
#     chrome_options.add_argument("--headless=new")  # ä½¿ç”¨æ–°ç‰ˆHeadlessæ¨¡å¼
#     chrome_options.add_argument("--disable-gpu")
#     chrome_options.add_argument("--no-sandbox")
#     chrome_options.add_argument("--disable-dev-shm-usage")
    
#     # ååçˆ¬å…³é”®é…ç½®
#     chrome_options.add_argument("--disable-blink-features=AutomationControlled")
#     chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
#     chrome_options.add_experimental_option("useAutomationExtension", False)
    
#     # å®Œæ•´User-Agentè®¾ç½®
#     chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
    
#     # å…¶ä»–ä¼˜åŒ–å‚æ•°
#     chrome_options.add_argument("--start-maximized")
#     chrome_options.add_argument("--window-size=1920,1080")
#     chrome_options.add_argument("--disable-infobars")
#     chrome_options.add_argument("--disable-extensions")
#     chrome_options.add_argument("--disable-notifications")
#     chrome_options.add_argument("--disable-popup-blocking")
    
#     # éšè—WebDriverç‰¹å¾
#     chrome_options.add_argument("--disable-web-security")
#     chrome_options.add_argument("--allow-running-insecure-content")
    
#     # ä»£ç†è®¾ç½®
#     if proxy:
#         if "@" in proxy:  # æœ‰è®¤è¯çš„ä»£ç† user:pass@ip:port
#             auth, host_port = proxy.split("@")
#             proxy = f"{host_port}"  # Chromeä»£ç†æ’ä»¶åªéœ€è¦host:port
#             chrome_options.add_extension(_create_proxy_auth_extension(auth))
#         else:  # æ— è®¤è¯ä»£ç† ip:port
#             host_port = proxy
            
#         # è®¾ç½®ä»£ç†
#         chrome_options.add_argument(f'--proxy-server={host_port}')
#         print(f"ä½¿ç”¨ä»£ç†: {proxy}")
    
#     driver = None
#     try:
#         driver = webdriver.Chrome(options=chrome_options)
        
#         # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
#         driver.set_page_load_timeout(timeout)
        
#         # è®¿é—®ç›®æ ‡URL
#         driver.get(url)
        
#         # æ™ºèƒ½ç­‰å¾…ï¼ˆå…ˆç­‰é¡µé¢åŸºæœ¬åŠ è½½å®Œæˆï¼‰
#         WebDriverWait(driver, timeout).until(
#             lambda d: d.execute_script("return document.readyState") == "complete"
#         )
        
#         # æ˜¾å¼ç­‰å¾…ç›®æ ‡divï¼ˆæœ€é•¿ç­‰å¾…timeoutç§’ï¼‰
#         itinerary_div = WebDriverWait(driver, timeout).until(
#             EC.presence_of_element_located((By.CSS_SELECTOR, "div.daily_itinerary_con"))
#         )
        
#         content = itinerary_div.get_attribute('outerHTML')
        
#         # ç¡®ä¿ç›®å½•å­˜åœ¨
#         os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
#         with open(output_file, 'w', encoding='utf-8') as f:
#             f.write(content)
        
#         print(f"âœ… æˆåŠŸä¿å­˜: {output_file}")
#         return True
        
#     except TimeoutException:
#         print(f"âŒ é¡µé¢åŠ è½½è¶…æ—¶ {url} (è¶…æ—¶æ—¶é—´: {timeout}ç§’)")
#         return False
#     except Exception as e:
#         print(f"âŒ æå–å¤±è´¥ {url}: {str(e)}")
#         return False
#     finally:
#         if driver:
#             driver.quit()


def extract_dynamic_itinerary(url, output_file, timeout=15, proxy=None):
    """
    å¢å¼ºç‰ˆåŠ¨æ€å†…å®¹æå–å‡½æ•°ï¼ˆå¸¦å¼‚å¸¸é‡è¯•æœºåˆ¶ï¼‰
    :param url: ç›®æ ‡URL
    :param output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    :param timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    :return: æ˜¯å¦æˆåŠŸ
    """
    # chrome_options = Options()
    # chrome_options.add_argument("--headless")
    # chrome_options.add_argument("--disable-gpu")
    # chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
    chrome_options = Options()
    
    # åŸºç¡€æ— å¤´æ¨¡å¼é…ç½®
    chrome_options.add_argument("--headless=new")  # ä½¿ç”¨æ–°ç‰ˆHeadlessæ¨¡å¼
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    
    # ååçˆ¬å…³é”®é…ç½®
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)
    
    # å®Œæ•´User-Agentè®¾ç½®ï¼ˆå»ºè®®ä»çœŸå®æµè§ˆå™¨å¤åˆ¶ï¼‰
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
    
    # å…¶ä»–ä¼˜åŒ–å‚æ•°
    chrome_options.add_argument("--start-maximized")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-infobars")
    chrome_options.add_argument("--disable-extensions")
    chrome_options.add_argument("--disable-notifications")
    chrome_options.add_argument("--disable-popup-blocking")
    
    # éšè—WebDriverç‰¹å¾ï¼ˆé‡è¦ï¼ï¼‰
    chrome_options.add_argument("--disable-web-security")
    chrome_options.add_argument("--allow-running-insecure-content")
    
    driver = None
    try:
        driver = webdriver.Chrome(options=chrome_options)
        driver.get(url)
        
        # æ™ºèƒ½ç­‰å¾…ï¼ˆå…ˆç­‰é¡µé¢åŸºæœ¬åŠ è½½å®Œæˆï¼‰
        WebDriverWait(driver, timeout).until(
            lambda d: d.execute_script("return document.readyState") == "complete"
        )
        
        # æ˜¾å¼ç­‰å¾…ç›®æ ‡divï¼ˆæœ€é•¿ç­‰å¾…timeoutç§’ï¼‰
        itinerary_div = WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.daily_itinerary_con"))
        )
        
        content = itinerary_div.get_attribute('outerHTML')
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… æˆåŠŸä¿å­˜: {output_file}")
        return True
        
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥ {url}: {str(e)}")
        return False
    finally:
        if driver:
            driver.quit()

def batch_extract_itineraries(input_file, output_dir, proxy=None):
    """
    æ‰¹é‡å¤„ç†URLæ–‡ä»¶ä¸­çš„æ¯ä¸ªé“¾æ¥
    :param input_file: åŒ…å«URLçš„æ–‡æœ¬æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªURLï¼‰
    :param output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    """
    # è¯»å–URLåˆ—è¡¨
    with open(input_file, 'r', encoding='utf-8') as f:
        urls = [line.strip() for line in f if line.strip()]
    
    print(f"ğŸ“‹ å…±å‘ç° {len(urls)} ä¸ªå¾…å¤„ç†URL")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    success_count = 0
    for i, url in enumerate(urls, 1):
        print(f"\nğŸ” æ­£åœ¨å¤„ç† ({i}/{len(urls)}): {url}")
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼ˆä½¿ç”¨URLä¸­çš„äº§å“IDï¼‰
        product_id = url.split('/')[-1].split('?')[0].replace('p', '')[:10]
        output_file = os.path.join(output_dir, f"æ”»ç•¥_{product_id}.html")
        
        if os.path.exists(output_file):
            print(f"â© å·²å­˜åœ¨æ–‡ä»¶: {output_file}ï¼Œè·³è¿‡")
            success_count += 1
            continue

        # æ‰§è¡Œæå–
        if extract_dynamic_itinerary(url, output_file, proxy=proxy):
            success_count += 1
        
        # ç¤¼è²Œå»¶è¿Ÿï¼ˆé¿å…è¢«å°ï¼‰
        time.sleep(1)
    
    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼æˆåŠŸ {success_count}/{len(urls)} ä¸ª")

def render_html_to_text(html_file, output_dir=None, wait_time=3):
    """
    å°†HTMLæ–‡ä»¶æ¸²æŸ“åè½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬
    :param html_file: HTMLæ–‡ä»¶è·¯å¾„
    :param output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤åŒHTMLç›®å½•ï¼‰
    :param wait_time: æ¸²æŸ“ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    :return: ç”Ÿæˆçš„æ–‡æœ¬æ–‡ä»¶è·¯å¾„
    """
    


    try:
        # å‡†å¤‡è¾“å‡ºè·¯å¾„
        if not output_dir:
            output_dir = os.path.dirname(html_file)
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡æœ¬æ–‡ä»¶å
        base_name = os.path.splitext(os.path.basename(html_file))[0]
        txt_file = os.path.join(output_dir, f"{base_name}.txt")
        
        if os.path.exists(txt_file):
            print(f"â© å·²å­˜åœ¨æ–‡æœ¬æ–‡ä»¶: {txt_file}ï¼Œè·³è¿‡")
            return txt_file
        
        # é…ç½®æµè§ˆå™¨
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--disable-gpu")
        driver = webdriver.Chrome(options=chrome_options)
        # æ„å»ºæœ¬åœ°æ–‡ä»¶URL
        abs_path = os.path.abspath(html_file)
        file_url = f"file://{abs_path}"
        
        # åŠ è½½æœ¬åœ°HTMLæ–‡ä»¶
        driver.get(file_url)
        time.sleep(wait_time)  # ç­‰å¾…æ¸²æŸ“å®Œæˆ

        # è·å–æ¸²æŸ“åçš„æ–‡æœ¬
        visible_text = driver.find_element(By.TAG_NAME, "body").text
        


        # ä¿å­˜æ–‡æœ¬
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(visible_text)
        
        print(f"âœ… æ–‡æœ¬å·²ä¿å­˜: {txt_file}")
        return txt_file

    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {str(e)}")
        return None
    finally:
        driver.quit()

def batch_html_to_text(input_dir, output_dir=None, method='selenium'):
    """
    æ‰¹é‡è½¬æ¢HTMLä¸ºæ–‡æœ¬
    :param input_dir: åŒ…å«HTMLçš„ç›®å½•
    :param output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤åˆ›å»ºtext_outputå­ç›®å½•ï¼‰
    :param method: 'selenium' æˆ– 'bs4'
    """
    if not output_dir:
        output_dir = os.path.join(input_dir, 'text_output')
    os.makedirs(output_dir, exist_ok=True)
    
    success = 0
    for file in os.listdir(input_dir):
        if file.endswith('.html'):
            html_path = os.path.join(input_dir, file)
            print(f"\nå¤„ç†: {file}")
            
            if method == 'selenium':
                result = render_html_to_text(html_path, output_dir)
            
            if result:
                success += 1
    
    print(f"\nğŸ‰ è½¬æ¢å®Œæˆï¼æˆåŠŸ {success}/{len(os.listdir(input_dir))} ä¸ªæ–‡ä»¶")
    print(f"æ–‡æœ¬æ–‡ä»¶ä¿å­˜åœ¨: {os.path.abspath(output_dir)}")

# def process_city_urls_multi_thread(input_dir, output_base_dir):
#     """
#     å¤šçº¿ç¨‹å¤„ç†å‡½æ•°ï¼šè¯»å–åŸå¸‚URLæ–‡ä»¶ï¼Œçˆ¬å–æ”»ç•¥å¹¶è½¬æ¢ä¸ºæ–‡æœ¬
#     :param input_dir: åŒ…å«åŸå¸‚URLæ–‡ä»¶çš„ç›®å½•
#     :param output_base_dir: è¾“å‡ºæ ¹ç›®å½•
#     """
#     # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
#     final_output_dir = os.path.join(output_base_dir, "æ—…æ¸¸æ”»ç•¥æ–‡æœ¬")
#     os.makedirs(final_output_dir, exist_ok=True)
    
#     # è·å–æ‰€æœ‰åŸå¸‚æ–‡ä»¶
#     city_files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]
    
#     # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ¯5ä¸ªåŸå¸‚ä¸€ç»„ï¼‰
#     task_queue = Queue()
#     for i in range(0, len(city_files), 5):
#         task_queue.put(city_files[i:i+5])
    
#     # çº¿ç¨‹é”ï¼ˆç”¨äºæ‰“å°è¾“å‡ºï¼‰
#     print_lock = threading.Lock()
    
#     def worker():
#         while not task_queue.empty():
#             try:
#                 files_batch = task_queue.get()
#                 for city_file in files_batch:
#                     # æå–åŸå¸‚åï¼ˆä»æ–‡ä»¶åï¼‰
#                     city_name = os.path.splitext(city_file)[0]
#                     city_url_file = os.path.join(input_dir, city_file)
                    
#                     # ä¸ºæ¯ä¸ªåŸå¸‚åˆ›å»ºå•ç‹¬ç›®å½•
#                     city_output_dir = os.path.join(final_output_dir, city_name)
#                     os.makedirs(city_output_dir, exist_ok=True)
                    
#                     with print_lock:
#                         print(f"\n{'='*40}")
#                         print(f"çº¿ç¨‹ {threading.current_thread().name} æ­£åœ¨å¤„ç†åŸå¸‚: {city_name}")
                    
#                     # ç¬¬ä¸€æ­¥ï¼šçˆ¬å–HTMLæ”»ç•¥
#                     html_dir = os.path.join(city_output_dir, "HTMLç‰ˆæœ¬")
#                     batch_extract_itineraries(city_url_file, html_dir)
                    
#                     # ç¬¬äºŒæ­¥ï¼šè½¬æ¢ä¸ºæ–‡æœ¬
#                     batch_html_to_text(html_dir, os.path.join(city_output_dir, "æ–‡æœ¬ç‰ˆæœ¬"))
                    
#                     with print_lock:
#                         print(f"åŸå¸‚ {city_name} å¤„ç†å®Œæˆï¼")
#             finally:
#                 task_queue.task_done()
    
#     # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹ï¼ˆæ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´çº¿ç¨‹æ•°é‡ï¼‰
#     num_threads = min(1, (len(city_files) + 4) // 5)  # æœ€å¤š8ä¸ªçº¿ç¨‹
#     threads = []
#     for i in range(num_threads):
#         t = threading.Thread(target=worker, name=f"CityWorker-{i+1}")
#         t.start()
#         threads.append(t)
    
#     # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
#     task_queue.join()
    
#     # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
#     for t in threads:
#         t.join()
    
#     print("æ‰€æœ‰åŸå¸‚å¤„ç†å®Œæˆï¼")

def process_city_urls_multi_thread(input_dir, output_base_dir, proxy_list):
    """
    å¤šçº¿ç¨‹å¤„ç†å‡½æ•°ï¼šè¯»å–åŸå¸‚URLæ–‡ä»¶ï¼Œçˆ¬å–æ”»ç•¥å¹¶è½¬æ¢ä¸ºæ–‡æœ¬
    æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ç‹¬ç«‹çš„ä»£ç†IP
    
    :param input_dir: åŒ…å«åŸå¸‚URLæ–‡ä»¶çš„ç›®å½•
    :param output_base_dir: è¾“å‡ºæ ¹ç›®å½•
    :param proxy_list: å¯ç”¨çš„ä»£ç†IPåˆ—è¡¨ï¼Œæ ¼å¼å¦‚ ["123.141.18.8:5031", "123.30.154.171:7777"]
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    final_output_dir = os.path.join(output_base_dir, "æ—…æ¸¸æ”»ç•¥æ–‡æœ¬")
    os.makedirs(final_output_dir, exist_ok=True)
    
    # è·å–æ‰€æœ‰åŸå¸‚æ–‡ä»¶
    city_files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]
    
    # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ¯5ä¸ªåŸå¸‚ä¸€ç»„ï¼‰
    task_queue = Queue()
    for i in range(0, len(city_files), 5):
        task_queue.put(city_files[i:i+5])
    
    # çº¿ç¨‹é”ï¼ˆç”¨äºæ‰“å°è¾“å‡ºå’Œä»£ç†IPç®¡ç†ï¼‰
    print_lock = threading.Lock()
    proxy_lock = threading.Lock()
    
    # ä»£ç†IPçŠ¶æ€å­—å…¸
    proxy_status = {proxy: {"available": True, "last_used": 0} for proxy in proxy_list}
    
    def get_proxy_for_thread():
        """ä¸ºçº¿ç¨‹è·å–ä¸€ä¸ªå¯ç”¨çš„ä»£ç†IP"""
        with proxy_lock:
            # ä¼˜å…ˆé€‰æ‹©æœ€è¿‘æœªä½¿ç”¨çš„å¯ç”¨ä»£ç†
            available_proxies = [p for p, status in proxy_status.items() if status["available"]]
            if not available_proxies:
                return None
            
            # æŒ‰æœ€åä½¿ç”¨æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€ä¹…æœªä½¿ç”¨çš„
            available_proxies.sort(key=lambda p: proxy_status[p]["last_used"])
            selected_proxy = available_proxies[0]
            proxy_status[selected_proxy]["last_used"] = time.time()
            return selected_proxy
    
    def mark_proxy_status(proxy, is_available):
        """æ›´æ–°ä»£ç†IPçŠ¶æ€"""
        with proxy_lock:
            if proxy in proxy_status:
                proxy_status[proxy]["available"] = is_available
                if not is_available:
                    print(f"æ ‡è®°ä»£ç† {proxy} ä¸ºä¸å¯ç”¨")
    
    def worker():
        """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
        # ä¸ºå½“å‰çº¿ç¨‹è·å–ä»£ç†
        proxy = get_proxy_for_thread()
        if not proxy:
            with print_lock:
                print(f"çº¿ç¨‹ {threading.current_thread().name} å¯åŠ¨å¤±è´¥: æ— å¯ç”¨ä»£ç†")
            return
            
        proxy_dict = {
            "http": f"http://{proxy}",
            "https": f"http://{proxy}"
        }
        
        with print_lock:
            print(f"çº¿ç¨‹ {threading.current_thread().name} å¯åŠ¨ï¼Œä½¿ç”¨ä»£ç†: {proxy}")
        
        while not task_queue.empty():
            try:
                files_batch = task_queue.get()
                for city_file in files_batch:
                    # æå–åŸå¸‚åï¼ˆä»æ–‡ä»¶åï¼‰
                    city_name = os.path.splitext(city_file)[0]
                    city_url_file = os.path.join(input_dir, city_file)
                    
                    # ä¸ºæ¯ä¸ªåŸå¸‚åˆ›å»ºå•ç‹¬ç›®å½•
                    city_output_dir = os.path.join(final_output_dir, city_name)
                    os.makedirs(city_output_dir, exist_ok=True)
                    
                    with print_lock:
                        print(f"\n{'='*40}")
                        print(f"çº¿ç¨‹ {threading.current_thread().name} (ä»£ç†: {proxy}) æ­£åœ¨å¤„ç†åŸå¸‚: {city_name}")
                    
                    try:
                        # ç¬¬ä¸€æ­¥ï¼šçˆ¬å–HTMLæ”»ç•¥ï¼ˆä¼ å…¥ä»£ç†ï¼‰
                        html_dir = os.path.join(city_output_dir, "HTMLç‰ˆæœ¬")
                        batch_extract_itineraries(city_url_file, html_dir, proxy=proxy_dict["https"])
                        
                        # ç¬¬äºŒæ­¥ï¼šè½¬æ¢ä¸ºæ–‡æœ¬
                        batch_html_to_text(html_dir, os.path.join(city_output_dir, "æ–‡æœ¬ç‰ˆæœ¬"))
                        
                        with print_lock:
                            print(f"åŸå¸‚ {city_name} å¤„ç†å®Œæˆï¼")
                    except Exception as e:
                        with print_lock:
                            print(f"å¤„ç†åŸå¸‚ {city_name} æ—¶å‡ºé”™: {str(e)}")
                        # æ ‡è®°ä»£ç†å¯èƒ½æœ‰é—®é¢˜
                        # mark_proxy_status(proxy, False)
                        # è·å–æ–°ä»£ç†
                        new_proxy = get_proxy_for_thread()
                        if new_proxy:
                            proxy = new_proxy
                            proxy_dict = {
                                "http": f"http://{proxy}",
                                "https": f"http://{proxy}"
                            }
                            with print_lock:
                                print(f"çº¿ç¨‹ {threading.current_thread().name} åˆ‡æ¢ä¸ºæ–°ä»£ç†: {proxy}")
                        else:
                            with print_lock:
                                print(f"çº¿ç¨‹ {threading.current_thread().name} æ— å¯ç”¨ä»£ç†ï¼Œç»ˆæ­¢ä»»åŠ¡")
                            return
            finally:
                task_queue.task_done()
    
    # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹ï¼ˆæ ¹æ®CPUæ ¸å¿ƒæ•°å’Œä»£ç†æ•°é‡è°ƒæ•´çº¿ç¨‹æ•°é‡ï¼‰
    num_threads = min(len(proxy_list), (len(city_files) + 4) // 5, 2)  # æœ€å¤š8ä¸ªçº¿ç¨‹æˆ–ä»£ç†æ•°é‡
    threads = []
    for i in range(num_threads):
        t = threading.Thread(target=worker, name=f"CityWorker-{i+1}")
        t.start()
        threads.append(t)
    
    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    task_queue.join()
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
    for t in threads:
        t.join()
    
    print("æ‰€æœ‰åŸå¸‚å¤„ç†å®Œæˆï¼")



load_dotenv()

API_URL = os.getenv("API_URL")
MODEL_NAME = os.getenv("MODEL_NAME")
API_KEY = os.getenv("API_KEY")

class AIChatAPI:
    def __init__(self):
        self.conversation_history: List[Dict] = []
        
    def send_request(self, messages: List[Dict], temperature: float = 0.7, max_tokens: int = 2048) -> Dict :
        """å‘é€APIè¯·æ±‚å¹¶ä¿å­˜åˆ°å†å²è®°å½•"""
        headers = {"Content-Type": "application/json"}
        payload = {
            "model": MODEL_NAME,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens
        }

        if API_KEY:
            headers["Authorization"] = f"Bearer {API_KEY}"
        
        try:
            assert API_URL is not None
            response = requests.post(API_URL, headers=headers, json=payload)
            response.raise_for_status()
            result = response.json()
            if 'choices' in result:
                self.conversation_history.extend([
                    messages[-1],  # ç”¨æˆ·æœ€åä¸€æ¡æ¶ˆæ¯
                    {"role": "assistant", "content": result['choices'][0]['message']['content']}
                ])
            return result
        except requests.exceptions.RequestException as e:
            print(f"APIè¯·æ±‚å¤±è´¥: {str(e)}")
            return {}

def txt_guide_to_md_guide(input_root, output_root):
    with open("/home/JingpengQin/travel_guide/code/txt2Markdown_Prompt.txt", "r", encoding="utf-8") as f:
        base_prompt = f.read()

# é…ç½®è·¯å¾„
    #input_root = "E:/æ¸…åå­¦ä¹ /å¤§ä¸‰å¤å­£å®ä¹ /ä»£ç /çˆ¬è™«è·å–æ—…æ¸¸æ”»ç•¥/è¾“å‡ºç»“æœ/æ•´ç†åçš„æ”»ç•¥/æ–‡æœ¬ç‰ˆæœ¬"
    #output_root = "E:/æ¸…åå­¦ä¹ /å¤§ä¸‰å¤å­£å®ä¹ /ä»£ç /çˆ¬è™«è·å–æ—…æ¸¸æ”»ç•¥/è¾“å‡ºç»“æœ/æ•´ç†åçš„æ”»ç•¥/ç²¾æ ‡åMarkdownç‰ˆæœ¬+å¯¹åº”æ–‡æœ¬ç‰ˆæœ¬/ç²¾æ ‡Markdownç‰ˆæœ¬"

    def count_days(md_content):
        """è®¡ç®—Markdownå†…å®¹ä¸­åŒ…å«çš„'Day'æ•°é‡"""
        return len(re.findall(r'## Day \d+', md_content))

    def get_output_filename(txt_filename, md_content):
        """ç”Ÿæˆå¸¦å‡ æ—¥æ¸¸æ ‡è®°çš„è¾“å‡ºæ–‡ä»¶å"""
        base_name = os.path.splitext(txt_filename)[0]
        days = count_days(md_content)
        return f"{base_name}_{days}æ—¥æ¸¸.md"

    def is_file_processed(output_dir, base_filename):
        """æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåæ–‡ä»¶ï¼ˆä¸è€ƒè™‘å‡ æ—¥æ¸¸æ ‡è®°ï¼‰"""
        for filename in os.listdir(output_dir):
            if filename.startswith(base_filename) and filename.endswith('.md'):
                return True
        return False

# éå†æ‰€æœ‰åŸå¸‚æ–‡ä»¶å¤¹
    for city_folder in os.listdir(input_root):
        city_input_path = os.path.join(input_root, city_folder)
        city_output_path = os.path.join(output_root, city_folder)
    
    # è·³è¿‡éç›®å½•æ–‡ä»¶
        if not os.path.isdir(city_input_path):
            continue
    
        print(f"\n{'='*40}")
        print(f"æ­£åœ¨å¤„ç†åŸå¸‚: {city_folder}")
    
    # åˆ›å»ºåŸå¸‚å¯¹åº”çš„è¾“å‡ºç›®å½•
        os.makedirs(city_output_path, exist_ok=True)
    
    # éå†åŸå¸‚ä¸‹çš„æ‰€æœ‰txtæ–‡ä»¶
        for txt_file in os.listdir(city_input_path):
            if not txt_file.endswith('.txt'):
                continue
            
        # è·å–åŸºç¡€æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            base_filename = os.path.splitext(txt_file)[0]
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåæ–‡ä»¶ï¼ˆä¸è€ƒè™‘å‡ æ—¥æ¸¸æ ‡è®°ï¼‰
            if is_file_processed(city_output_path, base_filename):
                print(f"â© å·²å­˜åœ¨ç›¸å…³æ–‡ä»¶: {base_filename}*.md")
                continue
            
            try:
            # æ„é€ å®Œæ•´è·¯å¾„
                txt_path = os.path.join(city_input_path, txt_file)
            
            # è¯»å–æ–‡æœ¬å†…å®¹
                with open(txt_path, 'r', encoding='utf-8') as f:
                    txt_content = f.read()
            
            # æ„é€ å®Œæ•´Prompt
                full_prompt = base_prompt + "\n\n" + txt_content
            
            # è°ƒç”¨Qwen API
                response = AIChatAPI().send_request(
                    messages=[{"role": "user", "content": full_prompt}],
                    temperature=0.7,
                    max_tokens=2048
                )
            
            # ç”Ÿæˆå¸¦å‡ æ—¥æ¸¸æ ‡è®°çš„æ–‡ä»¶å
                md_filename = get_output_filename(txt_file, response.text)
                md_path = os.path.join(city_output_path, md_filename)
            
            # ä¿å­˜Markdownæ–‡ä»¶
                with open(md_path, 'w', encoding='utf-8') as f:
                    f.write(response.text)
            
                print(f"âœ… è½¬æ¢æˆåŠŸ: {txt_file} â†’ {md_filename}")
            
            # ç¤¼è²Œå»¶è¿Ÿï¼ˆé¿å…APIé™æµï¼‰
                time.sleep(2)
            
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ {txt_file}: {str(e)}")
            # ä¿å­˜é”™è¯¯æ—¥å¿—
                with open(os.path.join(output_root, "error_log.txt"), 'a') as f:
                    f.write(f"{city_folder}/{txt_file} å¤„ç†å¤±è´¥: {str(e)}\n")

    print("\næ‰€æœ‰åŸå¸‚å¤„ç†å®Œæˆ!")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    URL_FILES_DIR = "/home/JingpengQin/travel_guide/process_data/æ—…æ¸¸æ”»ç•¥url"  # å­˜æ”¾åŸå¸‚URLæ–‡æœ¬æ–‡ä»¶çš„ç›®å½•
    OUTPUT_DIR = "/home/JingpengQin/travel_guide/process_data/è¾“å‡ºç»“æœ"       # è¾“å‡ºæ ¹ç›®å½•
    proxies = [
    # "85.215.64.49:8O",        # æ³¨æ„ï¼šç«¯å£"BO"å¯èƒ½æ— æ•ˆ
    # "38.54.71.67:8O",         # åŒä¸Š
    "193.151.141.17:8O8O",     # ç«¯å£æ ¼å¼å¼‚å¸¸
    "123.141.181.32:5031",      # æœ‰æ•ˆ
    "123.30.154.171:7777",    # æœ‰æ•ˆ
    "18.171.55.201:3128",     # æœ‰æ•ˆ
    "51.81.245.3:17981",      # æœ‰æ•ˆ(æ³¨æ„IPç¬¬ä¸‰æ®µ812è¶…è¿‡255)
    "156.38.112.11:8O",       # ç«¯å£æ— æ•ˆ
    "123.141.181.86:5031"      # æœ‰æ•ˆ
]
    # æ‰§è¡Œå¤„ç†
    process_city_urls_multi_thread(URL_FILES_DIR, OUTPUT_DIR, proxies)
    print("\næ‰€æœ‰åŸå¸‚å¤„ç†å®Œæ¯•! æ–‡æœ¬æ–‡ä»¶ä¿å­˜åœ¨: ", OUTPUT_DIR)